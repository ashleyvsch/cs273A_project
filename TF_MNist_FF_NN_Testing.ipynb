{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54672851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Sci. Comp. Imports\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "# create random number generator for later/throughout\n",
    "rng = np.random.default_rng(seed=120695)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28712729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the keras data set module:\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# with mnist model data is already partitioned into training and validation\n",
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d9dac",
   "metadata": {},
   "source": [
    "The data consists of 70,000 images of handwritten digits. The partition of the above data set is such that the training data set contains 60,000 images and the validation contains the other 10,000. Each images is a 28 by 28 2D array of integer values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dabda0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data matrix/array is \n",
      " (60000, 28, 28) \n",
      "The shape of the validation data matrix/array is \n",
      " (10000, 28, 28) \n",
      "and the data type for the training array is uint8\n",
      "and the data type for the validation array is uint8\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of the training data matrix/array is \\n {x_train.shape} \")\n",
    "print(f\"The shape of the validation data matrix/array is \\n {x_valid.shape} \")\n",
    "print(f\"and the data type for the training array is {x_train.dtype}\")\n",
    "print(f\"and the data type for the validation array is {x_valid.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae56a72",
   "metadata": {},
   "source": [
    "The images are greyscale images and so the values in the arrays are integers between 0 and 255 (inclusive) indication the white level brightness. Be below for conformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b15828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum values of images is 0 and the maximum is 255\n",
      "Here is a image for reference\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum values of images is {x_train.min()} and the maximum is {x_train.max()}\")\n",
    "print(f\"Here is a image for reference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88059c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The displayed image label is 3\n"
     ]
    }
   ],
   "source": [
    "idx = rng.integers(low=0, high=x_train.shape[0])\n",
    "image = x_train[idx]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print(f\"The displayed image label is {y_train[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff359aaa",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "Here is where we can get to experimenting and trying different things. So in deep learning there are things that can be done to make the data better to work with. In particular, for classifying the mnist data set, Nvidia tutorial suggests the 3 following data transformations/preparations:\n",
    "1. Flatten the image data, to simplify the image input into the model\n",
    "2. Normalize the image data, to make the image input values easier to work with for the model\n",
    "3. Categorize the labels, to make the label values easier to work with for the model\n",
    "\n",
    "Now for simplicity I will only play around with the latter two of the preparations as I do not want to play around with other input times to the NN below. \n",
    "\n",
    "### Flatten (Reshape) the Image Data\n",
    "So apparently we can set things up to have the nueral net model accept 2D images, but it can simplify things by `flattening` the image into a single continuous array of $28\\times 28=784$ pixel values. Maybe at some point in time we can play around with 2D input for the model and see how the performance changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81c1d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train is now a (60000, 784) shaped array\n",
      "x_valid is now a (10000, 784) shaped array\n",
      "As an example here is the above 1D array of the above displayed image \n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  47 194 255 254 235 249\n",
      " 254 134   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  21  76  39  39  27  36 114 254 122   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0 254 135   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 106 244  40   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0  16 217 120   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 197 231   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  74 247  68   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  14 229 176   0   0\n",
      "  37  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  17 213 247 234 211 237 240 219 100   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  54\n",
      "  58  23  49  88 170 253 114   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 114 255  61\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 254 135   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 254 135   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  16 254  83   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  16 157 231  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 123 254  76   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   2 118 247 121   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  88 253 183   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  10 210 183  16   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 134 121   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(-1, 784)\n",
    "x_valid = x_valid.reshape(-1, 784)\n",
    "print(f\"x_train is now a {x_train.shape} shaped array\")\n",
    "print(f\"x_valid is now a {x_valid.shape} shaped array\")\n",
    "print(f\"As an example here is the above 1D array of the above displayed image \\n {x_train[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc59718",
   "metadata": {},
   "source": [
    "### Normalized and not nomalized data\n",
    "So as was mentioned above, one way to simplify things would be normalizing the data; in the case of this image data (integer pixel values) we could do that be mapping all the integer values from the range $0-255$ into the interval $[0,1]$. This can be done by a simple division of 255 and in this case this is the normalization as each pixel can only be an integer value between 0 and 255$. We for the purposes of trying different things and testing the validity of this claim will have normalized data and non-normalized data and compare the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81640fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of normalized data: float64\n",
      " Min of normalized: 0.0 and max is 1.0\n"
     ]
    }
   ],
   "source": [
    "norm_tr = x_train / 255\n",
    "norm_va = x_valid / 255\n",
    "# double check that the values are of type float and that they are between 0 and 1\n",
    "print(f\"Data type of normalized data: {norm_tr.dtype}\\n Min of normalized: {norm_tr.min()} and max is {norm_tr.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f764db",
   "metadata": {},
   "source": [
    "### Categorical encodeing\n",
    "One of the suggestions made to simply the model is to use categorical encoding: transform the data labels so that each value is a collection of all the possible categories, with the actual catgory that this particular value is set as true. The reason for doing this, according to the Nvidia Deep Learning Fundamentals workshop is that \n",
    "> ... the labels for the images are integers between 0 and 9. Because these values represent a numerical range, the model might try to draw some conclusions about its performance based on how close to the correct numerical category it guesses.\n",
    "\n",
    "Specifically the transformation is that the values which are intended to be understood as categorical labels into a represenation that makes their categorical nature explicit to the model. As an example, if we had the labels/values of\n",
    "\n",
    "```python\n",
    "values = ['red', 'green', 'blue', 'green']\n",
    "```\n",
    "the categorical encoding would transform the above data labels to \n",
    "```python\n",
    "values = [ \n",
    "    [1, 0, 0]\n",
    "    [0, 1, 0]\n",
    "    [0, 0, 1]\n",
    "    [0, 1, 0]\n",
    "]\n",
    "```\n",
    "Apparently the NN would have a harder time to making sense of the first values array/list then this harder one. Now are labels are numeric values between 0-9. We will still use categorical encoding (see below what it looks like) but will also test a model without categorical encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aac139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec3a0328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten categorical encodings: \n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "the values from which the categories were transformed from:\n",
      "[5 0 4 1 9 2 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "num_categories = 10\n",
    "# use the keras library/wrapper function to create the categories\n",
    "y_tr_encoded = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_va_encoded = keras.utils.to_categorical(y_valid, num_categories)\n",
    "# take a look at what the categorical encoding looks like\n",
    "print(f\"First ten categorical encodings: \\n {y_tr_encoded[0:9]}\")\n",
    "print(f\"the values from which the categories were transformed from:\\n{y_train[0:9]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf71f8d",
   "metadata": {},
   "source": [
    "Basically the encoding changed the numeric label $x$ to the single dimensional array with the $x^{th}$ element a 1 and zeros elsewhere.\n",
    "\n",
    "## Create the Models\n",
    "In this notebook we will only be using forward feed neural networks (FFNN). We will save trying to use a convolusional neural network (CNN) on this classification problem for another notebook. So below we will create for models:\n",
    "1. A model that uses the normalized data and categorical encoding of the labels (i.e. norm_tr and y_tr_encoded)\n",
    "2. Another model that uses the normalized data but the original data labels- no categorical encoding (i.e. norm_tr and y_train)\n",
    "3. A model with non-normalized (original) data but with categorically encoded data (i.e. x_train and y_tr_encoded)\n",
    "4. No simplification model; Non-normalized data and non-categorically encoded data labels (i.e. x_train and y_train)\n",
    "\n",
    "(What largely follows comes from the Nvidia workshop tutorial on the fundamentals of deep learning) \n",
    "### Instantiating the Model\n",
    "To start off we will use Keras's Sequential model class to instantiate an instance of a model that will have 3 series of layers that data will pass though in sequence (which is why I think that this is a forward feed network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d511df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# model numbers relate to the numbering (listing) in the above markdown cell\n",
    "model1 = Sequential() \n",
    "model2 = Sequential()\n",
    "model3 = Sequential()\n",
    "model4 = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b1c61e",
   "metadata": {},
   "source": [
    "### Creating the Input Layer\n",
    "Next, we will add the input layer. This layer will be *densely connected*, meaning that each neuron in it, and its weights, will affect every neuron in the next layer. To do this with Keras, we use Keras's [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e1cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb98be",
   "metadata": {},
   "source": [
    "The `units` argument specifies the number of neurons in the layer. We can play around with this number but I will note that the work shop says that Nvidia says that 512 is a good number from experimentation. In generally choosing the correct number of neurons is what puts the \"science\" in \"data science\" as it is a matter of capturing the statistical complexity of the dataset but can be, and often is, a difficult and time consuming thing to do. The task of classifying the MNIST data set, I (Erik) have found that with the following layer, the number of nuerons even as low as 20 still gave 95% and higher validation accuracy only after 10 epochs. That said, still feel free to play around with the number of neurons on each layerto see how it affects training and to start developing a sense for what this number means.\n",
    "\n",
    "The `input_shape` value specifies the shape of the incoming data which in our situation is a 1D array of 784 values. At a later time we can play around with the input shape maybe being (28, 28) which is the original way the MNIST images are stored.\n",
    "\n",
    "Regarding the activation function, there are a number of activation functions to choose from and the activation funciton can be set either through using the `Activation` layer or through the `activation` argument by all forward layers. The available activations are the follow: (1) rectified linear unit activation function `'relu'`, (2) sigmoid `'sigmoid'`, (3) softmax `'softmax'`, (4) softplus `'softplus'`, (5) softsign `'softsign'`, (6) hyperbolic tangent `'htan'`, (7) scaled exponential linear unit `'selu'`, (8) eponetial linear unit `'elu'`, (9) exponential `'exponential'` (10) custom function (lets not try this). For more about these activation funtion visit [here](https://keras.io/api/layers/activations/) for some keras documentation on the layers.\n",
    "\n",
    "At the moment let's just play with only on activation function. If we want to use different activation function to test different models with we can do that later and probably do so by creating some wrapper functions to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8b5b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dense(units=50, activation='relu', input_shape=(784,)))\n",
    "model2.add(Dense(units=50, activation='relu', input_shape=(784,)))\n",
    "model3.add(Dense(units=50, activation='relu', input_shape=(784,)))\n",
    "model4.add(Dense(units=50, activation='relu', input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6bbe0",
   "metadata": {},
   "source": [
    "### Creating Hidden Layers:\n",
    "So to add layer to the model we just use the add method with the arguement the layer you want. [Here](https://keras.io/api/models/sequential/#add-method) is a bit documention on the sequential model class and details on the add class at the very bottom. For now we will add 1 densely connected hidden layer. Note if we wanted to remove a layer it seems that we could use the pop method instead of add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5880e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dense(units=50, activation='relu'))\n",
    "model2.add(Dense(units=50, activation='relu'))\n",
    "model3.add(Dense(units=50, activation='relu'))\n",
    "model4.add(Dense(units=50, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f0dfdf",
   "metadata": {},
   "source": [
    "### Create the output layer\n",
    "Finally, we will add an output layer. This layer uses the activation function `softmax` which will result in each of the layer's values being a probability between 0 and 1 and will result in all the outputs of the layer adding to 1. In this case, since the network is to make a guess about a single image belonging to 1 of 10 possible categories, there will be 10 outputs. Each output gives the model's guess (a probability) that the image belongs to that specific class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "987ee04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dense(units=10, activation='softmax'))\n",
    "model2.add(Dense(units=10, activation='softmax'))\n",
    "model3.add(Dense(units=10, activation='softmax'))\n",
    "model4.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01e794",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "We can use the summary method from the model class to get a summer of the layers, the number of parameters of the model we have created. Since we have create all the models with the same layers, nodes per layer, and activation functions per layer, the summary of any of the 4 models will be the same so we only display on summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77f8f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 42,310\n",
      "Trainable params: 42,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636a3e6",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "So we have yet to give the model some sort of loss function for it to optimize against the parameters as well as metric to maximize. This is done when the model is [compiled](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile). There is a number of arguments to give the compile function but here only worry about the loss function and the metrics and leave the rest to there default values (though we may want to look into them). Now the matter of loss functions ther are a [number](https://keras.io/api/losses/) of them. At first will use the categorical cross entropy loss for the validation data that has been categorically encoded, in the one_hot format above and use the sparse categorical cross entroy for the other non categorically encoded labels as theses values are given as integers which this loss function expects. We also specify that we would like to track `accuracy` while the model trains, for other metrics see [here](https://keras.io/api/metrics/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a91113d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model4.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15b415",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "Now that we have prepared training and validation data, and a model, it's time to train our model with our training data, and verify it with its validation data.\n",
    "\n",
    "When fitting (training) a model with Keras, we use the model's [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method. It expects the following arguments:\n",
    "\n",
    "* The training data\n",
    "* The labels for the training data\n",
    "* The number of times it should train on the entire training dataset (called an *epoch*)\n",
    "* The validation or test data, and its labels\n",
    "\n",
    "Run the cells below to train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c642314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.2986 - accuracy: 0.9135 - val_loss: 0.1861 - val_accuracy: 0.9459\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1426 - accuracy: 0.9575 - val_loss: 0.1250 - val_accuracy: 0.9620\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1085 - accuracy: 0.9686 - val_loss: 0.1176 - val_accuracy: 0.9656\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0911 - accuracy: 0.9729 - val_loss: 0.0984 - val_accuracy: 0.9707\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0786 - accuracy: 0.9771 - val_loss: 0.1115 - val_accuracy: 0.9709\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0711 - accuracy: 0.9792 - val_loss: 0.1039 - val_accuracy: 0.9715\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 0.1125 - val_accuracy: 0.9688\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0599 - accuracy: 0.9828 - val_loss: 0.0995 - val_accuracy: 0.9744\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0555 - accuracy: 0.9837 - val_loss: 0.1149 - val_accuracy: 0.9718\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0528 - accuracy: 0.9851 - val_loss: 0.1244 - val_accuracy: 0.9720\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(\n",
    "    norm_tr, y_tr_encoded, epochs=10, verbose=1, validation_data=(norm_va, y_va_encoded)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7883934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 0.3019 - accuracy: 0.9115 - val_loss: 0.1557 - val_accuracy: 0.9534\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1482 - accuracy: 0.9558 - val_loss: 0.1295 - val_accuracy: 0.9617\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1148 - accuracy: 0.9663 - val_loss: 0.1144 - val_accuracy: 0.9653\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0953 - accuracy: 0.9721 - val_loss: 0.1139 - val_accuracy: 0.9673\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0837 - accuracy: 0.9757 - val_loss: 0.1118 - val_accuracy: 0.9692\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0748 - accuracy: 0.9781 - val_loss: 0.1065 - val_accuracy: 0.9710\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0686 - accuracy: 0.9808 - val_loss: 0.1117 - val_accuracy: 0.9705\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0639 - accuracy: 0.9819 - val_loss: 0.1102 - val_accuracy: 0.9719\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0582 - accuracy: 0.9840 - val_loss: 0.1181 - val_accuracy: 0.9724\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0554 - accuracy: 0.9847 - val_loss: 0.1208 - val_accuracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(\n",
    "    norm_tr, y_train, epochs=10, verbose=1, validation_data=(norm_va, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdb4e3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 1.4485 - accuracy: 0.8284 - val_loss: 0.4745 - val_accuracy: 0.9049\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.3856 - accuracy: 0.9233 - val_loss: 0.3109 - val_accuracy: 0.9378\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2906 - accuracy: 0.9408 - val_loss: 0.3321 - val_accuracy: 0.9372\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2505 - accuracy: 0.9476 - val_loss: 0.2707 - val_accuracy: 0.9430\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2426 - accuracy: 0.9493 - val_loss: 0.2402 - val_accuracy: 0.9537\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2302 - accuracy: 0.9536 - val_loss: 0.2894 - val_accuracy: 0.9540\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2207 - accuracy: 0.9558 - val_loss: 0.2489 - val_accuracy: 0.9536\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2214 - accuracy: 0.9584 - val_loss: 0.3654 - val_accuracy: 0.9467\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2181 - accuracy: 0.9591 - val_loss: 0.3423 - val_accuracy: 0.9512\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2269 - accuracy: 0.9604 - val_loss: 0.3109 - val_accuracy: 0.9602\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(\n",
    "    x_train, y_tr_encoded, epochs=10, verbose=1, validation_data=(x_valid, y_va_encoded)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69213208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 5ms/step - loss: 1.4256 - accuracy: 0.8306 - val_loss: 0.5064 - val_accuracy: 0.8990\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4521 - accuracy: 0.9102 - val_loss: 0.4351 - val_accuracy: 0.9135\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3844 - accuracy: 0.9243 - val_loss: 0.3951 - val_accuracy: 0.9180\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3404 - accuracy: 0.9343 - val_loss: 0.4293 - val_accuracy: 0.9270\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3233 - accuracy: 0.9384 - val_loss: 0.3771 - val_accuracy: 0.9302\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2998 - accuracy: 0.9439 - val_loss: 0.4037 - val_accuracy: 0.9300\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2912 - accuracy: 0.9475 - val_loss: 0.3653 - val_accuracy: 0.9439\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2804 - accuracy: 0.9512 - val_loss: 0.3804 - val_accuracy: 0.9424\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2688 - accuracy: 0.9532 - val_loss: 0.3836 - val_accuracy: 0.9487\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2789 - accuracy: 0.9529 - val_loss: 0.4189 - val_accuracy: 0.9402\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(\n",
    "    x_train, y_train, epochs=10, verbose=1, validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "518715a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(norm_tr.shape)\n",
    "print(y_tr_encoded.shape)\n",
    "print(norm_va.shape)\n",
    "print(y_va_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910726ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
